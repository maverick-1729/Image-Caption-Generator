# Image-Caption-Generator

Built an end-to-end image captioning model using EfficientNetB0 for visual feature extraction and a custom Transformer encoder–decoder for sequence generation. Trained on a subset of the MS COCO dataset with multi-caption supervision and evaluated using BLEU and CIDEr metrics. Implemented multiple decoding strategies including greedy decoding and beam search.

## Future Improvements
- Train with reinforcement learning (CIDEr-optimized loss)
- Replace the CNN with a Vision Transformer (ViT)
- CLIP-based image–text alignment
- Attention visualization
